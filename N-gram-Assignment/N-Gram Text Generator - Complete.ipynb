{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Text Generation\n",
    "\n",
    "In this assignment we'll generate text via various n-gram models. See the README for full instructions. For this whole assignment use a tokenization that folds to lowercase and removes tokens where `isalpha` is False. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "from nltk.book import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this assignment, I recommend you use the random.choices function. \n",
    "# here are some examples of its use.\n",
    "\n",
    "values = \"a b c d e f g\".split()\n",
    "weights = [1,1,5,5,10,10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g', 'g', 'g', 'f', 'e']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(population=values,weights=weights,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('g', 373),\n",
       " ('e', 199),\n",
       " ('f', 197),\n",
       " ('d', 107),\n",
       " ('c', 91),\n",
       " ('b', 17),\n",
       " ('a', 16)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(random.choices(population=values,weights=weights,k=1000)).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a function that generates text of a given length, using the probabilistic approach to glue one word to another. Have it start with a text and the desired length of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unigram(text,length=10) : ##Creating a function that will generate unigrams of length 10\n",
    "    \n",
    "    #Place each word in the text provided into a list\n",
    "    tokens= []\n",
    "    for word in text:  \n",
    "        tokens.append(word)\n",
    "    \n",
    "    #normalize list of tokens by making all elements lowercase and removing non-alphabetic characters\n",
    "    clean_tokens = []\n",
    "    \n",
    "    clean_tokens=[w.lower() for w in tokens if w.isalpha()]\n",
    "    \n",
    "    \n",
    "    # Now use random.choices to select `length` from clean_tokens and return them\n",
    "    \n",
    "    results=random.choices(population = clean_tokens, k=length)\n",
    "    \n",
    "    return(\" \".join(results)) #Return results separated by a space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now play around with the various texts, generating nonsense sentences from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person for the satisfaction murder of through oil the pip\n"
     ]
    }
   ],
   "source": [
    "print(generate_unigram(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of dare which mind groom ever eagerly sight time thence\n"
     ]
    }
   ],
   "source": [
    "print(generate_unigram(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there dam pouting is have join hi join i gay\n"
     ]
    }
   ],
   "source": [
    "print(generate_unigram(text5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same thing, but have it work with bigrams. This is harder, since you have a \"current word\" you want to glue text onto. The parameter \"start\" will give you a word to start with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigram(text,length=10,start=None) :\n",
    "    #Creating empty lists for lowercased text and results\n",
    "    lc_text= [] \n",
    "    results= []\n",
    "    \n",
    "    for tokens in text: #Lowercasing all text and removing non-alphabetic characters\n",
    "        if tokens.isalpha(): \n",
    "            lc_text.append(tokens.lower())\n",
    "\n",
    "    if not start : #The starting point will be one random selection from the population of lc_text list items\n",
    "        results.append(random.choices(population = lc_text, k=1)[0]) ##Add the starting point word to the list of results\n",
    "       \n",
    "    \n",
    "    else :  #If the lowercase starting word isn't in the text...\n",
    "        start=start.lower() \n",
    "        if start not in lc_text :\n",
    "            print(f\"The starting word, {start}, isn't in the text!\")\n",
    "            return(\"\")\n",
    "        \n",
    "        else: ##Otherwise add start word to results list\n",
    "            \n",
    "            results.append(start)\n",
    "    \n",
    "    lc_fd = FreqDist(nltk.bigrams(lc_text)) #Create a frequency distribution of bigrams in lc_text\n",
    "    \n",
    "    while len(results) < length:  ##While the length of the results list is less than 10\n",
    "        bigram_candidates = []\n",
    "        for pair in lc_fd:  #For each pair in the frequency distribution\n",
    "            if pair[0]==results[-1]:  #if the first word in the pair is the most recently added word in the results list\n",
    "                bigram_candidates.append(pair) #Add the word pair to the bigram candidates list\n",
    "                \n",
    "        next_pair = random.choices(population = bigram_candidates) #The next pair in the results list will be a random selection from bigram_candidates\n",
    "        results.append(next_pair[0][1])\n",
    "        \n",
    "    \n",
    "    return(\" \".join(results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the articles word till a bull poor stubb go hand'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_bigram(text1,10,\"the\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the tallest politely decided regard inevitable delay and parties stood'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_bigram(text2,10,\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the missing part dum de dum du dummmm pm alohas'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_bigram(text5,10,\"the\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
