{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Groups Function Building\n",
    "\n",
    "Below, I build a function that compares two corpuses by providing statistics for each one based on its tokens that provide length, lexical diversity, unique tokens, top words used, and ratios that look at how often one word appears in corpus one compared to corpus two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function that will process two different corpuses and provide some basic comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_groups(corpus_1, corpus_2, num_words, ratio_cutoff):\n",
    "    \n",
    "    ##Creating a dictionary for the results\n",
    "    results = {'one': [],\n",
    "               'two': [],\n",
    "               'one_vs_two': {'ratios': []},\n",
    "               'two_vs_one': {'ratios':[]}}\n",
    "    \n",
    "    #Opening each file\n",
    "    open_corpus1 = open(corpus_1, \"r\", encoding = \"Latin-1\")\n",
    "    open_corpus2 = open(corpus_2, \"r\", encoding = \"Latin-1\")\n",
    "    \n",
    "    read_c1 = open_corpus1.read()\n",
    "    read_c2 = open_corpus2.read()\n",
    "    \n",
    "    tokenize_c1 = nltk.word_tokenize(read_c1)\n",
    "    tokenize_c2 = nltk.word_tokenize(read_c2)\n",
    "    \n",
    "    ##Cleaning the tokens\n",
    "    c1_clean_tokens = []\n",
    "    c2_clean_tokens = []\n",
    "    \n",
    "    for tokens in tokenize_c1:\n",
    "        if tokens not in sw and tokens.isalpha():\n",
    "            c1_clean_tokens.append(tokens.lower())\n",
    "            \n",
    "    for tokens in tokenize_c2:\n",
    "        if tokens not in sw and tokens.isalpha():\n",
    "            c2_clean_tokens.append(tokens.lower())\n",
    "    \n",
    "    #Basic Statistics\n",
    "    unique_tokens_c1= len(set(c1_clean_tokens))\n",
    "    unique_tokens_c2= len(set(c2_clean_tokens))\n",
    "                   \n",
    "    lexical_diversity_c1= lexical_diversity(c1_clean_tokens)\n",
    "    lexical_diversity_c2= lexical_diversity(c2_clean_tokens)\n",
    "                   \n",
    "    top_words_c1= Counter(c1_clean_tokens).most_common(num_words)\n",
    "    top_words_c2= Counter(c2_clean_tokens).most_common(num_words)\n",
    "\n",
    "    all_lengths_1 = []\n",
    "    num_of_strings_1 = len(c1_clean_tokens)\n",
    "\n",
    "    for item in c1_clean_tokens:\n",
    "        string_size = len(item)\n",
    "        all_lengths_1.append(string_size)\n",
    "        total_size = sum(all_lengths_1)\n",
    "    ave_size_1 = float(total_size) / float(num_of_strings_1)              \n",
    "    \n",
    "    all_lengths_2=[]\n",
    "    num_of_strings_2=len(c2_clean_tokens)\n",
    "    \n",
    "    for item in c2_clean_tokens:\n",
    "        string_size = len(item)\n",
    "        all_lengths_2.append(string_size)\n",
    "        total_size= sum(all_lengths_2)\n",
    "    ave_size_2 = float(total_size) / float(num_of_strings_2)\n",
    "    \n",
    "    #Trying to generate num_words amount of words with highest one v two ratios\n",
    "    ratio_cutoff_words_1=set()               \n",
    "    for words in c1_clean_tokens : ##Only words that are used a certain amount of times are allowed\n",
    "        if c1_clean_tokens.count(words) >= ratio_cutoff:\n",
    "            \n",
    "            ratio_cutoff_words_1.add(words)\n",
    "    \n",
    "    freq_list_1=[] \n",
    "    for word in ratio_cutoff_words_1: ##Create a new list of times each word appears divided by length of clean tokens\n",
    "                 \n",
    "        p1=((c1_clean_tokens.count(word))/len(c1_clean_tokens))\n",
    "        item=word,p1\n",
    "        freq_list_1.append(item)\n",
    "           \n",
    "    ratio_cutoff_words_2 = set()       \n",
    "    for words in c2_clean_tokens: ##Only words that are used a certain amount of times are allowed\n",
    "        if c2_clean_tokens.count(words) >= ratio_cutoff:\n",
    "            \n",
    "            ratio_cutoff_words_2.add(words)\n",
    "    \n",
    "    freq_list_2=[] \n",
    "    for word in ratio_cutoff_words_2:  ##Create a new list of times each word appears divided by length of clean tokens\n",
    "               \n",
    "        p2=((c2_clean_tokens.count(word))/len(c2_clean_tokens))\n",
    "        item=word,p2\n",
    "        freq_list_2.append(item)\n",
    "        \n",
    "    ##Now I have two lists that contain each corpus' words and their frequencies\n",
    "    ##I need to make a new list that divides each frequency of each word\n",
    "    #in corpus 1 divided by freq in corpus 2\n",
    "    \n",
    "    \n",
    "    \n",
    "    one_vs_two_ratios=[]\n",
    "    \n",
    "    for word1,freq1 in freq_list_1:\n",
    "        for word2,freq2 in freq_list_2:\n",
    "            if word1==word2:\n",
    "                ratio=freq1/freq2\n",
    "                pair=word2,ratio\n",
    "                one_vs_two_ratios.append(pair)\n",
    "        \n",
    "    ##Taking num_words amount of the highest ratio words        \n",
    "    one_vs_two_ratios.sort(reverse=True)\n",
    "    \n",
    "    cutoff_words=one_vs_two_ratios[0:num_words]\n",
    "    \n",
    "    results['one_vs_two']= {'ratios':cutoff_words}   \n",
    "    \n",
    "    \n",
    "    ##Doing the same for two vs one\n",
    "    \n",
    "    two_vs_one_ratios=[]\n",
    "    \n",
    "    for word1,freq1 in freq_list_1:\n",
    "        for word2,freq2 in freq_list_2:\n",
    "            if word1==word2:\n",
    "                ratio=freq2/freq1\n",
    "                pair=word2,ratio\n",
    "                two_vs_one_ratios.append(pair)\n",
    "        \n",
    "    ##Taking num_words amount of the highest ratio words        \n",
    "    two_vs_one_ratios.sort(reverse=True)\n",
    "    \n",
    "    cutoff_words2=two_vs_one_ratios[0:num_words]\n",
    "    \n",
    "    \n",
    "    ##Inserting the summary stats into the dictionary\n",
    "    \n",
    "    \n",
    "    results['two_vs_one']= {'ratios':cutoff_words2}\n",
    "                   \n",
    "    results['one'] = {\"tokens\": [len(c1_clean_tokens)],\n",
    "                     \"unique_tokens\": [unique_tokens_c1],\n",
    "                     \"avg_token_length\": [ave_size_1],\n",
    "                     \"lexical_diversity\": [lexical_diversity_c1],\n",
    "                     \"top_words\": [top_words_c1]}\n",
    "    results['two'] = {\"tokens\": [len(c2_clean_tokens)],\n",
    "                      \"unique_tokens\": [unique_tokens_c2],\n",
    "                      \"avg_token_length\": [ave_size_2],\n",
    "                      \"lexical_diversity\": [lexical_diversity_c2],\n",
    "                      \"top_words\": [top_words_c2]}               \n",
    "   \n",
    "\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Republican/Democratic Conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_cutoff=5\n",
    "num_words=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1=\"Combined_Republican.txt\"\n",
    "\n",
    "file_2=\"Combined_Democratic.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': {'tokens': [48677],\n",
       "  'unique_tokens': [6882],\n",
       "  'avg_token_length': [5.854797953859112],\n",
       "  'lexical_diversity': [0.1413809396634961],\n",
       "  'top_words': [[('i', 1177),\n",
       "    ('trump', 751),\n",
       "    ('president', 742),\n",
       "    ('america', 426),\n",
       "    ('we', 347),\n",
       "    ('american', 335),\n",
       "    ('people', 304),\n",
       "    ('donald', 295),\n",
       "    ('country', 288),\n",
       "    ('the', 286)]]},\n",
       " 'two': {'tokens': [43545],\n",
       "  'unique_tokens': [6118],\n",
       "  'avg_token_length': [5.6596624181880815],\n",
       "  'lexical_diversity': [0.1404983350556895],\n",
       "  'top_words': [[('i', 910),\n",
       "    ('joe', 703),\n",
       "    ('biden', 644),\n",
       "    ('us', 448),\n",
       "    ('president', 398),\n",
       "    ('and', 373),\n",
       "    ('we', 333),\n",
       "    ('speaker', 329),\n",
       "    ('people', 305),\n",
       "    ('america', 253)]]},\n",
       " 'one_vs_two': {'ratios': [('your', 1.2779576156530366),\n",
       "   ('young', 0.5659526583606304),\n",
       "   ('you', 1.059721776672287),\n",
       "   ('york', 3.354638741089221),\n",
       "   ('yet', 2.546084788108742),\n",
       "   ('yes', 0.4472851654785628),\n",
       "   ('years', 2.1876310820678797),\n",
       "   ('year', 0.6890609306021103),\n",
       "   ('yeah', 0.3354638741089221),\n",
       "   ('wrong', 1.1501618540877327)]},\n",
       " 'two_vs_one': {'ratios': [('your', 0.7824985647031806),\n",
       "   ('young', 1.76693224287815),\n",
       "   ('you', 0.9436439091967855),\n",
       "   ('york', 0.2980946913154974),\n",
       "   ('yet', 0.3927598973413648),\n",
       "   ('yes', 2.2357101848662304),\n",
       "   ('years', 0.4571154653072218),\n",
       "   ('year', 1.4512504708780791),\n",
       "   ('yeah', 2.9809469131549737),\n",
       "   ('wrong', 0.8694428496702007)]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_groups(file_1,file_2, num_words, ratio_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Democratic Convention to big.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_cutoff=5\n",
    "num_words=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1=\"big.txt\"\n",
    "\n",
    "file_2=\"Combined_Democratic.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': {'tokens': [582554],\n",
       "  'unique_tokens': [28560],\n",
       "  'avg_token_length': [6.083523587512917],\n",
       "  'lexical_diversity': [0.049025498065415396],\n",
       "  'top_words': [[('i', 7632),\n",
       "    ('the', 7134),\n",
       "    ('said', 3463),\n",
       "    ('one', 3299),\n",
       "    ('may', 2549)]]},\n",
       " 'two': {'tokens': [43545],\n",
       "  'unique_tokens': [6118],\n",
       "  'avg_token_length': [5.6596624181880815],\n",
       "  'lexical_diversity': [0.1404983350556895],\n",
       "  'top_words': [[('i', 910),\n",
       "    ('joe', 703),\n",
       "    ('biden', 644),\n",
       "    ('us', 448),\n",
       "    ('president', 398)]]},\n",
       " 'one_vs_two': {'ratios': [('your', 1.5910738379127576),\n",
       "   ('young', 0.9534239201298882),\n",
       "   ('you', 1.07062758922844),\n",
       "   ('york', 1.8219931113682166),\n",
       "   ('yet', 2.8059412650025704)]},\n",
       " 'two_vs_one': {'ratios': [('your', 0.6285063434339697),\n",
       "   ('young', 1.048851385922609),\n",
       "   ('you', 0.9340315998401101),\n",
       "   ('york', 0.5488494955115693),\n",
       "   ('yet', 0.3563866473160421)]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_groups(file_1,file_2, num_words, ratio_cutoff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
